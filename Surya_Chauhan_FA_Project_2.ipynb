{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92as2SUq5N2Z",
        "outputId": "a393209c-b449-49d0-df45-ddc85efde0a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-12-27 09:40:03--  http://setup.johnsnowlabs.com/colab.sh\n",
            "Resolving setup.johnsnowlabs.com (setup.johnsnowlabs.com)... 51.158.130.125\n",
            "Connecting to setup.johnsnowlabs.com (setup.johnsnowlabs.com)|51.158.130.125|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://setup.johnsnowlabs.com/colab.sh [following]\n",
            "--2021-12-27 09:40:03--  https://setup.johnsnowlabs.com/colab.sh\n",
            "Connecting to setup.johnsnowlabs.com (setup.johnsnowlabs.com)|51.158.130.125|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/master/scripts/colab_setup.sh [following]\n",
            "--2021-12-27 09:40:04--  https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/master/scripts/colab_setup.sh\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1275 (1.2K) [text/plain]\n",
            "Saving to: ‘STDOUT’\n",
            "\n",
            "-                   100%[===================>]   1.25K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-12-27 09:40:04 (73.3 MB/s) - written to stdout [1275/1275]\n",
            "\n",
            "setup Colab for PySpark 3.0.3 and Spark NLP 3.3.4\n",
            "Installing PySpark 3.0.3 and Spark NLP 3.3.4\n",
            "\u001b[K     |████████████████████████████████| 209.1 MB 49 kB/s \n",
            "\u001b[K     |████████████████████████████████| 133 kB 58.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 198 kB 69.8 MB/s \n",
            "\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!wget http://setup.johnsnowlabs.com/colab.sh -O - | bash\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LOAIQjXg5Ojb",
        "outputId": "408cfdea-d9b1-4bb2-ea3f-23e1924f86b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-12-27 09:40:57--  http://setup.johnsnowlabs.com/colab.sh\n",
            "Resolving setup.johnsnowlabs.com (setup.johnsnowlabs.com)... 51.158.130.125\n",
            "Connecting to setup.johnsnowlabs.com (setup.johnsnowlabs.com)|51.158.130.125|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://setup.johnsnowlabs.com/colab.sh [following]\n",
            "--2021-12-27 09:40:57--  https://setup.johnsnowlabs.com/colab.sh\n",
            "Connecting to setup.johnsnowlabs.com (setup.johnsnowlabs.com)|51.158.130.125|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/master/scripts/colab_setup.sh [following]\n",
            "--2021-12-27 09:40:58--  https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/master/scripts/colab_setup.sh\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1275 (1.2K) [text/plain]\n",
            "Saving to: ‘colab.sh’\n",
            "\n",
            "colab.sh            100%[===================>]   1.25K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-12-27 09:40:58 (56.3 MB/s) - ‘colab.sh’ saved [1275/1275]\n",
            "\n",
            "#!/bin/bash\n",
            "\n",
            "#default values for pyspark, spark-nlp, and SPARK_HOME\n",
            "SPARKNLP=\"3.3.4\"\n",
            "PYSPARK=\"3.0.3\"\n",
            "\n",
            "while getopts s:p: option\n",
            "do\n",
            " case \"${option}\"\n",
            " in\n",
            " s) SPARKNLP=${OPTARG};;\n",
            " p) PYSPARK=${OPTARG};;\n",
            " esac\n",
            "done\n",
            "\n",
            "echo \"setup Colab for PySpark $PYSPARK and Spark NLP $SPARKNLP\"\n",
            "export JAVA_HOME=\"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
            "\n",
            "if [[ \"$PYSPARK\" == \"3.1\"* ]]; then\n",
            "  echo \"Installing PySpark $PYSPARK and Spark NLP $SPARKNLP\"\n",
            "elif [[ \"$PYSPARK\" == \"3.0\"* ]]; then\n",
            "  echo \"Installing PySpark $PYSPARK and Spark NLP $SPARKNLP\"\n",
            "elif [[ \"$PYSPARK\" == \"2\"* ]]; then\n",
            "  echo \"Installing PySpark $PYSPARK and Spark NLP $SPARKNLP\"\n",
            "  apt-get update\n",
            "  apt-get purge -y openjdk-11* -qq > /dev/null && sudo apt-get autoremove -y -qq > /dev/null\n",
            "  apt-get install -y openjdk-8-jdk-headless -qq > /dev/null\n",
            "\n",
            "  export SPARK_HOME=$SPARKHOME\n",
            "  export JAVA_HOME=\"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
            "\n",
            "  wget -q \"https://downloads.apache.org/spark/spark-2.4.8/spark-2.4.8-bin-hadoop2.7.tgz\" > /dev/null\n",
            "  tar -xvf spark-2.4.8-bin-hadoop2.8.tgz > /dev/null\n",
            "  SPARKHOME=\"/content/spark-2.4.8-bin-hadoop2.7\"\n",
            "else\n",
            "  export JAVA_HOME=\"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
            "  PYSPARK=\"3.0.3\"\n",
            "fi\n",
            "\n",
            "\n",
            "# Install pyspark spark-nlp\n",
            "! pip install --upgrade -q pyspark==$PYSPARK spark-nlp==$SPARKNLP findspark\n"
          ]
        }
      ],
      "source": [
        "!wget http://setup.johnsnowlabs.com/colab.sh \n",
        "\n",
        "! cat /content/colab.sh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "id": "7uCXppdL5Ogk"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# 2.1 spark related\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.sql import SparkSession\n",
        "import pyspark.sql.functions as F\n",
        "from pyspark.sql.types import DoubleType, StringType,StructField,StructType\n",
        "#Replace part of string with another string\n",
        "from pyspark.sql.functions import regexp_replace\n",
        "\n",
        "# 2.2 Spark-nlp related\n",
        "import sparknlp\n",
        "from sparknlp.base import *\n",
        "from sparknlp.annotator import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ublKZRwd5Od0"
      },
      "outputs": [],
      "source": [
        "# 2.3 Create Spark session\n",
        "#     And start sparknlp\n",
        "\n",
        "spark = sparknlp.start()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "PhBw6HuL5ObW"
      },
      "outputs": [],
      "source": [
        "# 2.4 Show multiple command outputs from a cell\n",
        "\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"all\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BX4iTp2Z5OY2",
        "outputId": "2455aff8-1f51-4d3d-b415-68cd0d099571"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "analyze_sentiment download started this may take some time.\n",
            "Approx size to download 4.9 MB\n",
            "[OK!]\n",
            "{'checked': ['Financial', 'News'], 'document': ['Financial News '], 'sentiment': ['negative'], 'token': ['Financial', 'News'], 'sentence': ['Financial News']}\n"
          ]
        }
      ],
      "source": [
        "from sparknlp.pretrained import PretrainedPipeline\n",
        "pipeline = PretrainedPipeline('analyze_sentiment', lang = 'en')\n",
        "result =  pipeline.annotate(\"Financial News \")\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BDeLunpq5OWA",
        "outputId": "ec207123-100b-4b9b-c451-022068eb108e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n"
          ]
        }
      ],
      "source": [
        "# 2.3 Mount gdrive to read data\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "rjza4Pi16w4X"
      },
      "outputs": [],
      "source": [
        "# 4.0 Read data directly in spark a normal manner:\n",
        "\n",
        "df = spark.read.csv(\n",
        "                      path = '/gdrive/MyDrive/FA Projects/all-data (1).csv',\n",
        "                      inferSchema=True,\n",
        "                      header=True\n",
        "                      )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9G4NwIzA7dOv",
        "outputId": "a665c3cf-6df8-41c9-812a-1394954de400"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+--------------------+\n",
            "|  Review|               Tweet|\n",
            "+--------+--------------------+\n",
            "| neutral|According to Gran...|\n",
            "| neutral|Technopolis plans...|\n",
            "|negative|The international...|\n",
            "|positive|With the new prod...|\n",
            "|positive|According to the ...|\n",
            "|positive|FINANCING OF ASPO...|\n",
            "|positive|For the last quar...|\n",
            "|positive|In the third quar...|\n",
            "|positive|Operating profit ...|\n",
            "|positive|Operating profit ...|\n",
            "|positive|TeliaSonera TLSN ...|\n",
            "|positive|STORA ENSO , NORS...|\n",
            "|positive|A purchase agreem...|\n",
            "|positive|Finnish Talentum ...|\n",
            "|positive|Clothing retail c...|\n",
            "|positive|Consolidated net ...|\n",
            "|positive|Foundries divisio...|\n",
            "|positive|HELSINKI ( AFX ) ...|\n",
            "|positive|Incap Contract Ma...|\n",
            "|positive|Its board of dire...|\n",
            "|positive|Lifetree was foun...|\n",
            "|positive|( Filippova ) A t...|\n",
            "|positive|MegaFon 's subscr...|\n",
            "|positive|Net income from l...|\n",
            "|positive|Net sales increas...|\n",
            "|positive|Net sales surged ...|\n",
            "|positive|Nordea Group 's o...|\n",
            "|positive|Operating profit ...|\n",
            "|positive|Operating profit ...|\n",
            "|positive|Operating profit ...|\n",
            "+--------+--------------------+\n",
            "only showing top 30 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.show(30)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.count() "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "USE5g1kqRx0r",
        "outputId": "592b42c1-1994-4456-fbb5-27b90718fc4f"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4846"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vCqei1vT7lyX",
        "outputId": "4bafd56f-1434-4e7d-8e1f-b1231ef9beb9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(Review='neutral', Tweet='According to Gran , the company has no plans to move all production to Russia , although that is where the company is growing .'),\n",
              " Row(Review='neutral', Tweet='Technopolis plans to develop in stages an area of no less than 100,000 square meters in order to host companies working in computer technologies and telecommunications , the statement said .'),\n",
              " Row(Review='negative', Tweet='The international electronic industry company Elcoteq has laid off tens of employees from its Tallinn facility ; contrary to earlier layoffs the company contracted the ranks of its office workers , the daily Postimees reported .'),\n",
              " Row(Review='positive', Tweet='With the new production plant the company would increase its capacity to meet the expected increase in demand and would improve the use of raw materials and therefore increase the production profitability .'),\n",
              " Row(Review='positive', Tweet=\"According to the company 's updated strategy for the years 2009-2012 , Basware targets a long-term net sales growth in the range of 20 % -40 % with an operating profit margin of 10 % -20 % of net sales .\")]"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ],
      "source": [
        "df.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "id": "aG7dmP-s8DhA"
      },
      "outputs": [],
      "source": [
        "# 5.0 First define a Spark schema:\n",
        "schema = StructType([ \\\n",
        "                     StructField(\"Tweet\",StringType(),True), \\\n",
        "                     StructField(\"Review\",StringType(),True), \\\n",
        "  ])\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "id": "jh2TWmfy8nf8"
      },
      "outputs": [],
      "source": [
        "# 5.1 Next read the data:\n",
        "\n",
        "trainDataset = spark.read  \\\n",
        "                 .option(\"quote\", \"\\\"\") \\\n",
        "                 .option('escape', \"\\\"\") \\\n",
        "                 .option(\"multiLine\", \"true\")  \\\n",
        "                 .option(\"schema\" , schema)  \\\n",
        "                 .option(\"header\", \"true\") \\\n",
        "                 .csv('/gdrive/MyDrive/FA Projects/all-data (1).csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lEj8U_5L8yJs",
        "outputId": "3c96bcfc-2d32-4f3f-9645-406a65a67f59"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+--------------------+\n",
            "|  Review|               Tweet|\n",
            "+--------+--------------------+\n",
            "| neutral|According to Gran...|\n",
            "| neutral|Technopolis plans...|\n",
            "|negative|The international...|\n",
            "|positive|With the new prod...|\n",
            "|positive|According to the ...|\n",
            "|positive|FINANCING OF ASPO...|\n",
            "|positive|For the last quar...|\n",
            "|positive|In the third quar...|\n",
            "|positive|Operating profit ...|\n",
            "|positive|Operating profit ...|\n",
            "|positive|TeliaSonera TLSN ...|\n",
            "|positive|STORA ENSO , NORS...|\n",
            "|positive|A purchase agreem...|\n",
            "|positive|Finnish Talentum ...|\n",
            "|positive|Clothing retail c...|\n",
            "|positive|Consolidated net ...|\n",
            "|positive|Foundries divisio...|\n",
            "|positive|HELSINKI ( AFX ) ...|\n",
            "|positive|Incap Contract Ma...|\n",
            "|positive|Its board of dire...|\n",
            "+--------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4846"
            ]
          },
          "metadata": {},
          "execution_count": 117
        }
      ],
      "source": [
        "# 5.2 The result shows complete match with pandas:\n",
        "trainDataset.show()\n",
        "trainDataset.count() "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J6tQnwUV81W9",
        "outputId": "a79b5028-e1ad-48fe-dbcb-daf2b8ebfc8b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+-----+\n",
            "|  Review|count|\n",
            "+--------+-----+\n",
            "| neutral| 2879|\n",
            "|positive| 1363|\n",
            "|negative|  604|\n",
            "+--------+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 5.3 Distribution of classes:\n",
        "from pyspark.sql.functions import col\n",
        "\n",
        "# 5.3.1\n",
        "trainDataset.groupBy(\"Review\") \\\n",
        "    .count() \\\n",
        "    .orderBy(col(\"count\").desc()) \\\n",
        "    .show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vjGR_9n189of",
        "outputId": "e233d66e-0acc-415c-8d20-f4d51733c2cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Dataset Count: 3888\n",
            "Test Dataset Count: 958\n"
          ]
        }
      ],
      "source": [
        "(trainingData, testData) = trainDataset.randomSplit([0.8, 0.2], seed = 100)\n",
        "\n",
        "# 6.0.1\n",
        "print(\"Training Dataset Count: \" + str(trainingData.count()))\n",
        "print(\"Test Dataset Count: \" + str(testData.count()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "In9SXutj9Ubd",
        "outputId": "2b055991-4bf3-4d26-8dad-47983da7eec1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lemma_antbnc download started this may take some time.\n",
            "Approximate size to download 907.6 KB\n",
            "[OK!]\n"
          ]
        }
      ],
      "source": [
        "#pipelinig for data cleaning\n",
        "# 6.1\n",
        "document_assembler = DocumentAssembler() \\\n",
        "    .setInputCol(\"Tweet\") \\\n",
        "    .setOutputCol(\"document\")\n",
        "\n",
        "# 6.2    \n",
        "tokenizer = Tokenizer() \\\n",
        "    .setInputCols([\"document\"]) \\\n",
        "    .setOutputCol(\"token\")\n",
        "\n",
        "# 6.3      \n",
        "normalizer = Normalizer() \\\n",
        "    .setInputCols([\"token\"]) \\\n",
        "    .setOutputCol(\"normalized\")\n",
        "\n",
        "# 6.4\n",
        "stopwords_cleaner = StopWordsCleaner()\\\n",
        "    .setInputCols(\"normalized\")\\\n",
        "    .setOutputCol(\"cleanTokens\")\\\n",
        "    .setCaseSensitive(False)\n",
        "\n",
        "# 6.5\n",
        "lemma = LemmatizerModel.pretrained('lemma_antbnc') \\\n",
        "    .setInputCols([\"cleanTokens\"]) \\\n",
        "    .setOutputCol(\"lemma\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nNjt9AbA-NMy",
        "outputId": "3578aee6-5be4-4912-a8cc-507d9f0b762b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "glove_100d download started this may take some time.\n",
            "Approximate size to download 145.3 MB\n",
            "[OK!]\n"
          ]
        }
      ],
      "source": [
        "# 7.0\n",
        "glove_embeddings = WordEmbeddingsModel().pretrained() \\\n",
        "      .setInputCols([\"document\",'lemma'])\\\n",
        "      .setOutputCol(\"embeddings\")\\\n",
        "      .setCaseSensitive(False)\n",
        "\n",
        "# 7.1\n",
        "embeddingsSentence = SentenceEmbeddings() \\\n",
        "      .setInputCols([\"document\", \"embeddings\"]) \\\n",
        "      .setOutputCol(\"sentence_embeddings\") \\\n",
        "      .setPoolingStrategy(\"AVERAGE\")\n",
        "\n",
        "# 7.2\n",
        "classsifierdl = ClassifierDLApproach()\\\n",
        "      .setInputCols([\"sentence_embeddings\"])\\\n",
        "      .setOutputCol(\"class\")\\\n",
        "      .setLabelColumn(\"Review\")\\\n",
        "      .setMaxEpochs(100)\\\n",
        "      .setEnableOutputLogs(True)\n",
        "      #.setOutputLogsPath('logs')\n",
        "\n",
        "# 7.3\n",
        "clf_pipeline = Pipeline(\n",
        "    stages=[document_assembler, \n",
        "            tokenizer,\n",
        "            normalizer,\n",
        "            stopwords_cleaner, \n",
        "            lemma, \n",
        "            glove_embeddings,\n",
        "            embeddingsSentence,\n",
        "            classsifierdl])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "id": "SQyjWKPJ-jsV"
      },
      "outputs": [],
      "source": [
        "# 8.0 Train \n",
        "\n",
        "clf_pipelineModel = clf_pipeline.fit(trainingData)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "id": "Szfs1jML-sdA"
      },
      "outputs": [],
      "source": [
        "preds = clf_pipelineModel.transform(testData)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sa4_QCmZi6AL",
        "outputId": "aab0449d-5293-47eb-84dc-38438fc9f549"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------------------------------------------------------------------+--------+---------+\n",
            "|                                                                           Tweet|  Review|   result|\n",
            "+--------------------------------------------------------------------------------+--------+---------+\n",
            "|( ADP News ) - Jan 22 , 2009 - Finnish mobile phones maker Nokia Oyj ( OMX : ...|negative|[neutral]|\n",
            "|- Net sales for the period are expected to fall well below that of last year ...|negative|[neutral]|\n",
            "|17 March 2011 - Goldman Sachs estimates that there are negative prospects for...|negative|[neutral]|\n",
            "|26 October 2010 - Finnish environmental management company Lassila & Tikanoja...|negative|[neutral]|\n",
            "|A tinyurl link takes users to a scamming site promising that users can earn t...|negative|[neutral]|\n",
            "|ADP News - Feb 13 , 2009 - Finnish retailer Kesko Oyj HEL : KESBV said today ...|negative|[neutral]|\n",
            "|ADPnews - Sep 28 , 2009 - Finnish silicon wafers maker Okmetic Oyj HEL : OKM1...|negative|[neutral]|\n",
            "|Acando AB ( ACANB SS ) fell 8.9 percent to 13.35 kronor , the lowest close si...|negative|[neutral]|\n",
            "|According to Arokarhu , some of the purchases that had been scanned into the ...|negative|[neutral]|\n",
            "|According to CEO Matti Perkonoja of the parent company HKScan , the company '...|negative|[neutral]|\n",
            "+--------------------------------------------------------------------------------+--------+---------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "preds.select('Tweet','Review',\"class.result\").show(10, truncate=80)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "id": "iTAkdEy8jJTJ"
      },
      "outputs": [],
      "source": [
        "# 9.2\n",
        "\n",
        "preds_df = preds.select('Review','Tweet',\"class.result\").toPandas()\n",
        "\n",
        "# The result is an array since in Spark NLP you can have multiple sentences.\n",
        "# Let's explode the array and get the item(s) inside of result column out\n",
        "\n",
        "# 9.3\n",
        "preds_df['result'] = preds_df['result'].apply(lambda x : x[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P8JDrCbDjfZT",
        "outputId": "dfdf907e-1089-4680-c1bd-c26505d86bc9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.00      0.00      0.00         0\n",
            "     neutral       0.92      0.71      0.80       734\n",
            "    positive       0.46      0.57      0.51       224\n",
            "\n",
            "    accuracy                           0.68       958\n",
            "   macro avg       0.46      0.43      0.44       958\n",
            "weighted avg       0.81      0.68      0.73       958\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "# 9.4 We are going to use sklearn to evalute \n",
        "#      the results on test dataset:\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# 9.5\n",
        "print (classification_report(preds_df['result'], preds_df['Review']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yavx2MPYjfWS"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "OtswkZUr1sTS"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Surya Chauhan_FA Project 2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}